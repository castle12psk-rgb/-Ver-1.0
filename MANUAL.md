# 해외감염병 감시 솔루션 (GIDS) 상세 명세서

---

## Part 1: 사용자 매뉴얼

### 1. 소개

**해외감염병 감시 솔루션(Global Infectious Disease Surveillance Solution, GIDS)**은 전 세계의 감염병 발생 정보를 실시간으로 수집, 분석, 시각화하여 대한민국 질병관리청 및 관련 공중 보건 기관의 신속하고 정확한 의사결정을 지원하는 지능형 플랫폼입니다.

본 매뉴얼은 GIDS의 각 기능별 화면 구성과 사용 방법을 상세히 안내합니다.

-   **실시간 정보 수집:** 자동화된 정보 수집 시스템의 현황을 모니터링합니다.
-   **AI 기반 정보 검증:** 수집된 정보의 신뢰도를 AI가 자동으로 검증하는 과정을 추적합니다.
-   **직관적 시각화:** 검증된 정보를 지도 기반으로 시각화하여 직관적인 상황 파악을 지원합니다.
-   **데이터 통계 및 정리:** 축적된 데이터를 기반으로 통계 분석 및 보고서를 생성합니다.

### 2. 실시간 정보 수집 현황

이 페이지는 전 세계 웹에서 감염병 정보를 수집하는 지능형 크롤러(Crawler)의 상태를 실시간으로 보여주는 통합 대시보드입니다.

**화면 구성 및 기능:**

1.  **도움말 아이콘 (`?`):** 페이지 제목 우측의 물음표 아이콘을 클릭하면 데이터 수집 및 처리 프로세스에 대한 상세한 인포그래픽을 포함한 도움말 팝업이 나타납니다.
2.  **핵심 지표 카드:**
    *   **총 데이터 소스:** 시스템이 정보를 수집하는 대상 기관(WHO, CDC 등) 및 미디어의 총 개수입니다.
    *   **활성 크롤러:** 현재 정상적으로 정보 수집 활동을 수행 중인 크롤러의 수입니다. 녹색으로 빛나는 효과는 시스템이 활발하게 작동 중임을 의미합니다.
    *   **24시간 내 수집된 정보:** 최근 24시간 동안 수집된 총 문서(기사, 보고서 등)의 수입니다. 숫자는 실시간으로 부드럽게 증가하여 동적인 현황을 보여줍니다.
3.  **데이터 소스 상세 현황:**
    *   **상태:** 각 크롤러의 현재 상태를 표시합니다.
        *   `Active (녹색)`: 정상 작동 중
        *   `Warning (노란색)`: 일시적 오류 또는 응답 지연 발생
        *   `Error (빨간색)`: 수집 실패 또는 접속 불가 상태
    *   **데이터 소스:** 정보 출처의 이름입니다.
    *   **최근 수집 시각:** 마지막으로 정보 수집을 성공한 시간입니다.
    *   **신규 문서:** 최근 수집 주기에서 발견된 새로운 문서의 수입니다.
    *   **로그:** `보기` 버튼 클릭 시, 해당 소스에 대한 상세한 실시간 로그를 팝업으로 확인할 수 있습니다. (예: 연결 시작, 문서 파싱, 오류 내역 등)
4.  **실시간 수집 피드:**
    *   가장 최근에 수집된 문서 정보를 시간, 출처와 함께 실시간으로 보여주는 로그 창입니다. 새로운 정보가 수집될 때마다 목록 상단에 추가됩니다.

### 3. AI 기반 정보 검증

수집된 정보가 사실인지, 허위 정보인지, 아니면 의견인지를 AI가 자동으로 판별하는 과정을 투명하게 보여주는 페이지입니다.

**화면 구성 및 기능:**

1.  **도움말 아이콘 (`?`):** AI 검증 프로세스와 여기에 사용되는 NLP, RAG 등의 핵심 기술에 대한 상세한 인포그래픽 도움말 팝업을 엽니다.
2.  **수집된 정보 피드:** AI 검증을 대기 중인 정보 목록입니다. 정보의 제목과 출처가 표시됩니다.
3.  **AI 검증 프로세스:**
    *   대기 중인 정보가 자동으로 이관되어 검증이 시작됩니다. 검증은 다음 3단계로 진행되며, 각 단계의 진행률과 결과가 실시간으로 표시됩니다.
    *   **Step 1: 텍스트 분류 (NLP):** 자연어 처리 기술로 텍스트의 내용을 분석하여 '사실', '허위', '의견'으로 1차 분류하고 초기 신뢰도를 계산합니다.
    *   **Step 2: RAG 기반 팩트체크:** 시스템이 보유한 신뢰도 높은 데이터베이스(질병청 내부 자료, WHO 보고서 등)에서 관련 근거를 검색(Retrieval)하고, 이를 바탕으로 AI가 원본 정보와 교차 검증하여 요약 보고서를 생성(Generation)합니다.
    *   **Step 3: 최종 판정:** 앞선 두 단계의 결과를 종합하여 최종 결론(사실/허위/의견)을 내리고, 객관적인 신뢰도 점수(%)를 산출합니다.
4.  **검증 완료:**
    *   AI 검증이 완료된 정보들이 최신순으로 정렬됩니다.
    *   각 항목은 최종 결과에 따라 `사실(녹색)`, `허위(빨간색)`, `의견(회색)`으로 명확하게 구분되어 표시됩니다.

### 4. 직관적 시각화 플랫폼

검증이 완료된 감염병 발생 정보를 인터랙티브 세계 지도 위에 표시하여, 전 세계 상황을 직관적으로 파악할 수 있게 합니다.

**화면 구성 및 기능:**

1.  **도움말 아이콘 (`?`):** 검증된 데이터가 지도 위에 시각화되기까지의 기술적 프로세스를 인포그래픽으로 설명하는 도움말 팝업을 엽니다.
2.  **필터 및 옵션:**
    *   **기간:** 특정 기간 내에 발생한 정보만 필터링합니다.
    *   **감염병 종류:** 특정 감염병(예: 뎅기열, 콜레라)만 선택하여 볼 수 있습니다.
    *   **위험 등급:** `높음`, `중간`, `낮음` 등급별로 정보를 필터링할 수 있습니다.
3.  **인터랙티브 지도:**
    *   감염병 발생 정보가 마커로 표시됩니다. 마커의 **색상**은 위험 등급(빨강: 높음, 주황: 중간, 노랑: 낮음), **크기**는 발생 규모, **깜빡임 효과**는 최신 주요 이벤트를 의미합니다.
    *   마우스 휠로 확대/축소, 드래그로 이동이 가능합니다.
    *   마커 클릭 시, 해당 이벤트의 요약 정보(위치, 발생일, 개요 등)가 담긴 팝업이 표시됩니다.
4.  **최근 이벤트 목록:**
    *   가장 최근에 발생한 주요 이벤트 목록입니다. 항목 클릭 시, 지도 중앙이 해당 위치로 자동 이동됩니다.
5.  **상세 보고서:**
    *   지도 위 정보 팝업에서 `상세 보고서 보기` 버튼을 클릭하면, 해당 감염병에 대한 통계, AI 분석, 권고 사항 등이 포함된 심층 분석 보고서 모달이 나타납니다. 이 보고서는 PDF로 다운로드하거나 공유할 수 있습니다.

### 5. 데이터 통계 및 정리

축적된 모든 데이터를 기반으로 다양한 통계 분석 결과를 제공하고, 정기 보고서를 생성하는 페이지입니다.

**화면 구성 및 기능:**

1.  **기간 설정 및 보고서 생성:**
    *   분석을 원하는 기간을 설정한 후, `보고서 생성` 버튼을 클릭하면 해당 기간의 모든 데이터를 종합한 PDF 형식의 공식 보고서가 생성됩니다.
2.  **핵심 지표 카드:**
    *   설정된 기간 동안의 **총 발생 건수**, **영향받은 국가 수**, **최다 발생 감염병**, **고위험 발생 건수** 등 핵심 요약 정보를 제공합니다.
3.  **통계 차트:**
    *   **국가별 신규 발생 현황:** 어느 국가에서 감염병이 가장 많이 발생했는지 막대 차트로 보여줍니다.
    *   **전 세계 감염병 발생 추이:** 시간의 흐름에 따른 감염병 발생 건수 변화를 꺾은선 그래프로 보여줍니다.
    *   **감염병 유형별 분포:** 전체 발생 건 중 각 감염병 유형(호흡기, 모기매개 등)이 차지하는 비중을 파이 차트로 보여줍니다.
4.  **최신 주요 감염병 정보:**
    *   가장 최근에 보고된 주요 감염병 목록을 표 형태로 제공하여 빠른 확인이 가능합니다.

---

## Part 2: GIDS 개발 스펙 및 기술 아키텍처

### 1. 시스템 목표 및 개요

전 세계 비정형/정형 데이터를 24/7 자동으로 수집하고, AI/LLM 기술을 통해 정보의 신뢰도를 검증하며, 이를 지리정보(GIS) 및 통계 데이터와 결합하여 정책 결정자에게 직관적인 인사이트를 제공하는 것을 목표로 합니다.

### 2. 핵심 프로세스

`데이터 수집` ➔ `데이터 저장 및 정제` ➔ `AI 검증` ➔ `데이터베이스 저장` ➔ `시각화 및 통계 분석`

### 3. 개발 기술 스택 (Technology Stack)

| 구분 | 기술 | 사유 |
| :--- | :--- | :--- |
| **프론트엔드** | **React, TypeScript** | 컴포넌트 기반 개발 및 타입 안정성을 통한 높은 유지보수성 확보 |
| | **Tailwind CSS** | 신속한 UI 프로토타이핑 및 일관된 디자인 시스템 구축 |
| | **Recharts** | 통계 페이지의 다양한 인터랙티브 차트 구현 |
| | **Mapbox / Leaflet** | 시각화 페이지의 고성능, 고품질 인터랙티브 지도 구현 (PostGIS와 연동) |
| **백엔드** | **Python, FastAPI** | 비동기 처리를 통한 고성능 API 서버 구축, AI/ML 생태계와 완벽한 호환성 |
| | **Celery, Redis** | 비동기 대규모 작업(크롤링, AI 검증) 처리를 위한 분산 작업 큐 시스템 |
| **데이터베이스** | **PostgreSQL + PostGIS** | 검증 완료된 정형 데이터 및 지리정보 데이터 저장/분석 (강력한 GIS 쿼리 지원) |
| | **Elasticsearch** | 수집된 원본 데이터의 전문(Full-text) 검색 및 로그 데이터 분석 |
| | **Vector DB (e.g., Pinecone, ChromaDB)** | RAG 시스템을 위한 텍스트 임베딩 벡터 저장 및 초고속 유사도 검색 |
| **인프라** | **AWS / GCP** | 확장성, 안정성, 다양한 관리형 서비스(S3, EC2, RDS 등) 활용 |
| | **Docker, Kubernetes (EKS/GKE)** | 마이크로서비스 아키텍처 기반의 안정적인 배포, 확장, 관리 |
| | **Message Queue (RabbitMQ/Kafka)** | 서비스 간의 비동기 통신을 통한 시스템 결합도 완화 및 데이터 파이프라인 안정성 확보 |
| | **CI/CD (GitHub Actions)** | 코드 통합, 테스트, 배포 자동화 |

### 4. AI/LLM 모델 아키텍처

AI 검증 모듈은 **마이크로서비스 아키텍처**로 설계하여 각 기능의 독립적인 확장 및 업데이트를 용이하게 합니다.

#### a. 데이터 수집 모듈 (Crawler Service)
-   **기술:** `Python`, `Scrapy` (웹 크롤링 프레임워크), `Selenium` (동적 페이지 크롤링), `BeautifulSoup`
-   **프로세스:**
    1.  **Targeting:** 관리자 페이지에서 설정된 데이터 소스(URL, API 엔드포인트) 목록을 주기적으로 확인.
    2.  **Crawling:** Scrapy와 Selenium을 이용해 웹 페이지/API 데이터를 병렬로 수집.
    3.  **Extraction & Preprocessing:** 수집된 원본(HTML, JSON)에서 본문 텍스트, 날짜, 위치 등 핵심 정보 추출 및 정제.
    4.  **Queueing:** 정제된 데이터를 JSON 형태로 Message Queue(Kafka)에 전송하여 AI 검증 모듈로 전달.

#### b. 정보 검증 모듈 (AI Verification Service)
-   **기술:** `Python`, `PyTorch`/`TensorFlow`, `Hugging Face Transformers`, `LangChain`
-   **프로세스 (3-Step):**

    1.  **텍스트 분류 (Classification Model):**
        *   **AI 모델:** 다국어 지원을 위해 사전 학습된 `XLM-RoBERTa` 또는 `mBERT` 모델을 "사실", "허위", "의견" 클래스로 Fine-tuning.
        *   **작동:** 입력된 텍스트의 의미론적 맥락을 분석하여 1차 분류 및 신뢰도 점수(Softmax 확률)를 출력.

    2.  **RAG 기반 팩트체크 (RAG Model):**
        *   **LLM 모델:** **Google Gemini Pro** 또는 **OpenAI GPT-4** (최신 정보 및 추론 능력 활용)
        *   **기술:** `LangChain` 프레임워크를 사용하여 RAG 파이프라인 구축.
        *   **작동:**
            i.  **Embedding & Query:** 입력된 텍스트의 핵심 주장을 `Sentence-BERT`와 같은 임베딩 모델을 통해 벡터로 변환.
            ii. **Retrieval:** 이 벡터를 **Vector DB**에 쿼리하여 가장 관련성 높은 신뢰 데이터(질병청 내부 문서, WHO 보고서 등 사전에 임베딩하여 저장된 데이터) N개를 검색.
            iii. **Generation:** 검색된 근거 데이터(Context)와 원본 텍스트를 LLM(Gemini/GPT-4)에 함께 입력. "다음 근거 자료를 바탕으로 원본 텍스트의 사실 여부를 검증하고, 그 이유를 요약 설명해줘" 와 같은 프롬프트를 통해 최종 검증 결과 및 요약 보고서를 생성.

    3.  **최종 판정 (Ensemble Logic):**
        *   1단계 분류 모델의 결과와 2단계 RAG 모델의 결과를 가중 평균 또는 로직 기반으로 종합하여 최종 판정 및 신뢰도 점수를 산출.
        *   결과를 `PostgreSQL` 데이터베이스에 저장.

#### c. 데이터 제공 모듈 (API Service)
-   **기술:** `Python`, `FastAPI`, `GeoJSON`
-   **프로세스:**
    1.  프론트엔드로부터의 요청(필터 조건 등)을 수신.
    2.  `PostgreSQL`에서 관련 데이터를 조회. `PostGIS`를 활용하여 지리 공간 쿼리 수행.
    3.  조회된 데이터를 프론트엔드에서 사용하기 쉬운 형태(JSON, GeoJSON)로 가공하여 응답.
    4.  통계 분석을 위한 집계(Aggregation) 쿼리를 수행하여 차트 데이터 제공.